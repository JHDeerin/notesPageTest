<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0" name="viewport"/>
<title>Jake's CS Notes - Game AI</title>
<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet"/>
<link href="../css/testStyle.css" rel="stylesheet"/>
<link href="../css/notePageStyle.css" rel="stylesheet"/>
<link href="../css/cs4731Theme.css" id="class-theme-styles" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" rel="stylesheet"/>
</head>
<body>
<script defer="" src="../js/wrapText.js"></script>
<script defer="" src="../js/pageTransitions.js"></script>
<nav class="nav-top">
<ul>
<li class="link-with-slash"><a href="../index.html"><i class="fas fa-home"></i></a></li>
<li><a href="#" id="class-title-link">Game AI</a></li>
</ul>
<ul class="note-links-slider"><li><a class="is-note-link" href="0_firstDay_1_7_19.html">0. First Day</a></li><li><a class="is-note-link" href="1_gameVsRegularAI_1_9_19.html">1. Game AI vs Regular AI</a></li><li><a class="is-note-link" href="2_introPathfinding_1_14_19.html">2. Intro to Pathfinding</a></li><li><a class="is-note-link" href="3_pathNetworks_1_16_19.html">3. Path Networks</a></li><li><a class="is-note-link" href="4_morePathNetworks_1_23_19.html">4. Path Networks (cont.)</a></li><li><a class="is-note-link" href="5_pathfindingBasics_1_30_19.html">5. Pathfinding Basics</a></li><li class="active-note-page"><a class="is-note-link" href="6_pathfindingCont_2_4_19.html">6. Pathfinding (cont.)</a></li><li><a class="is-note-link" href="7_groupsDecisions_2_6_19.html">7. Groups and Decision Making</a></li><li><a class="is-note-link" href="8_moreDecisionMaking_2_11_19.html">8. Decision Making (cont.)</a></li><li><a class="is-note-link" href="9_behaviorTrees_2_13_19.html">9. Behavior Trees</a></li><li><a class="is-note-link" href="10_rulesPlanning_2_18_19.html">10. Rules and Planning</a></li><li><a class="is-note-link" href="11_behaviorPlanning_2_20_19.html">11. Behavior Planning (cont.)</a></li><li><a class="is-note-link" href="12_hierarchicalTaskNetworks_2_27_19.html">12. Hierarchical Task Networks</a></li><li><a class="is-note-link" href="13_introProceduralGen_3_4_19.html">13. Intro. to Procedural Generation</a></li><li><a class="is-note-link" href="14_moreProcGen_3_6_19.html">14. Procedural Generation / Terrain Generation</a></li><li><a class="is-note-link" href="15_optimizationAlgos_3_11_19.html">15. Optimization Algorithms</a></li><li><a class="is-note-link" href="16_geneticAlgos_3_13_19.html">16. Genetic Algorithms (cont.)</a></li><li><a class="is-note-link" href="17_playerModeling_3_26_19.html">17. Player Modeling</a></li><li><a class="is-note-link" href="18_introRL_3_27_19.html">18. Intro. to Reinforcement Learning</a></li><li><a class="is-note-link" href="19_moreQLearning_4_1_19.html">19. Q-Learning (cont.)</a></li><li><a class="is-note-link" href="20_evenMoreRL_4_8_19.html">20. More Q-Learning/Intro. Deep Reinforcement Learning</a></li><li><a class="is-note-link" href="21_deepLearning_4_10_19.html">21. Deep Learning (cont.)</a></li><li><a class="is-note-link" href="22_deepRL_4_15_19.html">22. Deep Reinforcement Learning (cont.)</a></li><li><a class="is-note-link" href="23_contextFreeGrammars_4_17_19.html">23. Context-Free Grammars</a></li><li><a class="is-note-link" href="24_grammarsStories_4_22_19.html">24. Grammars (cont.) / Story Generation</a></li></ul>
</nav>
<main>
<a class="side-link is-note-link" href="5_pathfindingBasics_1_30_19.html"></a>
<article>
<!-- Actual note text goes into 'pre' -->
<pre id="text-width-ruler"></pre>
<pre class="main-note-text">//****************************************************************************//
//***************** Pathfinding (cont.)- February 4th, 2019 *****************//
//**************************************************************************//

- So, you survived both homework 3 AND the most boring Super Bowl ever - congratulations!
- Homework 4 is LITERALLY just implementing A* pathfinding for the agent - so, hopefully it won't be too stressful for you
    - However, there'll also be "gates" along the path that will randomly open and shut - in this case, the agent will need to check that its destination is still reachable and, if not, it'll have to calculate a new path
    - So, you basically implement A*, implement re-planning detection (i.e. what to do when a gate appears), and then re-calculating the path
        - There's also an optional part for extra credit: implementing smoothing like we talked about last week, where instead of blindly following the path nodes the agent is able to skip to the next visible node
            - You'll have to deal with what happens if its path is blocked when it's off the grid, of course
        - ...ANNNNNND an optional class-wide competition to collect all the resources in the most efficient path possible (i.e. least distance traveled)
- After this, homework 5 will be on decision-making/planning, which is when our agent will finally start looking like a real, honest-to-goodness game AI
-------------------------------------------------------------------------

- So, A* - you should know how to do it by now, we expand our open/closed lists (priority queue, for the open list), use our heuristics (known cost from start + estimated cost to goal), and then exclaim hoorays as a path is begotten
    - But, just in case any of you haven't seen it yet/are suffering from severe brain hemorrhaging, Professor Riedl will go through it in EXCRUCIATING detail
    - (...he very much wants to make sure no one is left behind on this...)

- Alright, 40 minutes of already-learned A* later ("I know, it's almost as boring as the Super Bowl"), let's introduce some complexities to this
    - A LOT of games do have a path network that's completely known in advance - but in some games (like RTSes), you might have a "fog of war" where you can only see a small part of the map initially, and have to learn more and more of the map over time
        - Besides not knowing what your opponent is doing, this is also a navigation problem; your agent might try to move straight towards a destination, find an obstacle in the way, and then backtrack - otherwise, it has an unfair advantage!
        - There are a few solutions to this:
            - Just ignore the problem, and pretend that the AI can see through the fog ("omniscient optimality" - this seems unfair)
            - "Life-long planning," where the agent only uses what it can see/knows about and assumes everything it can't see is open space
                - Now, as the agent sees more of the map, it will adjust its path accordingly
                - This is still "optimal," since the agent is acting correctly based on what information it knows - "optimistic optimality"
                    - Variants of this algorithm are what were used on the Mars rover, where it needs to plan conservative, safe paths several minutes ahead without human intervention
        - As it turns out, there're only a few differences between A* and life-long planning:

            1) Paths are contionuously being broken, so we need some measure of RE-PLANNING (i.e. running A* from scratch)
                - Of course, running it completely from scratch is kinda inefficient, so we can often use a variant called "D*" that remembers the search tree in-between searches, saving us computation (you don't need to do this for the homework)
            2) (...none significant enough for Professor Riedl to mention...)

- Alright, and that's all we really need to know for pathfinding in this class! this is a bottomless pit of interesting techniques, though, so don't think this is all there is to say on the matter - but it's enough to be dangerous

- So, with that being said, let's look at what we might want to call "advanced sterring" - ways of controlling our agent's movement that don't involve full-on pathfinding
    - One of the big, cool ways of doing this are FLOCKING algorithms for handling large groups of agents, like schools of fish, flocks of birds, etc.
        - This is surprisingly simple to do and get realistic-looking (although not biologically-realistic) results, involving 3 behaviors:
            - SEPARATION: move away from other 'boids' that are too close (don't wanna crash into people)
                - If things are too close, you compute a vector pointing the "most away" from all the too-close things, and start moving that way (vector of separation)
                - If you want to get fancier, instead of just doing a radius check around the boid, you can use an angle to only avoid things the boid can "see"
            - COHESION: Move toward the center-of-mass of the flock (don't wanna get eaten by predators)
                - Instead of checking against every single boid, just check against the ones we can see in the immediate neighborhood
            - ALIGNMENT: move in the same direction as everyone else (don't wanna be left behind)
                - Again, instead of checking against every single boid, just check against the ones we can see in the immediate neighborhood
        - Average all three of these vectors, throw in some basic steering for obstacle/predator avoidance, and presto! You get some cool emergent behavior!
            - To remind you, "emergent behavior" just means a simple set of rules that results in some complex-looking behavior
- So, 3 simple computations that result in really cool-looking behavior - cool!

- We'll start looking at some even cooler steering behaviors on Wednesday - come and bend an ear to what secrets I will disclose thence!</pre>
</article>
<a class="side-link is-note-link" href="7_groupsDecisions_2_6_19.html"></a>
</main>
</body>
</html>