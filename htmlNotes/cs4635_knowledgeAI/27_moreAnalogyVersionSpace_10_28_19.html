<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0" name="viewport"/>
<title>Jake's CS Notes - Knowledge-Based AI</title>
<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet"/>
<link href="../../css/testStyle.css" rel="stylesheet"/>
<link href="../../css/notePageStyle.css" rel="stylesheet"/>
<link href="../../css/cs4635Theme.css" id="class-theme-styles" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" rel="stylesheet"/>
</head>
<body>
<script defer="" src="../../js/wrapText.js"></script>
<script defer="" src="../../js/pageTransitions.js"></script>
<script async="" defer="" src="../../js/loadMathJax.js"></script>
<nav class="nav-top">
<ul>
<li class="link-with-slash"><a href="../../index.html"><i class="fas fa-home"></i></a></li>
<li><a href="#" id="class-title-link">Knowledge-Based AI</a></li>
</ul>
<ul class="note-links-slider"><li><a class="is-note-link" href="0_firstDay_8_19_19.html">0. First Day</a></li><li><a class="is-note-link" href="1_introKBAI_8_21_19.html">1. Introduction to KBAI (cont.)</a></li><li><a class="is-note-link" href="2_principlesOfKBAI_8_23_19.html">2. Principles of KBAI</a></li><li><a class="is-note-link" href="3_introFrames_8_26_19.html">3. Introduction to Frames</a></li><li><a class="is-note-link" href="4_moreFrames_8_28_19.html">4. Frames (cont.)</a></li><li><a class="is-note-link" href="5_semanticNets_8_30_19.html">5. Semantic Networks</a></li><li><a class="is-note-link" href="6_optionsGenTest_9_4_19.html">6. Choosing Options / Generate and Test</a></li><li><a class="is-note-link" href="7_genTestMeansEnd_9_6_19.html">7. Generate and Test / Means-End Analysis</a></li><li><a class="is-note-link" href="8_productionSys_9_9_19.html">8. Production Systems</a></li><li><a class="is-note-link" href="9_moreProductionSys_9_11_19.html">9. Production Systems</a></li><li><a class="is-note-link" href="10_caseBasedReasoning_9_13_19.html">10. Case-Based Reasoning</a></li><li><a class="is-note-link" href="11_moreCaseBased_9_16_19.html">11. Case-Based Reasoning (cont.)</a></li><li><a class="is-note-link" href="13_introToClassification_9_20_19.html">12. Classification Basics</a></li><li><a class="is-note-link" href="14_incrementalConceptLearning_9_23_19.html">13. Incremental Concept Learning</a></li><li><a class="is-note-link" href="15_conceptLogic_9_25_19.html">14. Concept Learning (cont.) / Logic</a></li><li><a class="is-note-link" href="16_moreLogic_9_30_19.html">15. Logic (cont.)</a></li><li><a class="is-note-link" href="17_evenMoreLogicPlanning_10_2_19.html">16. Logic (cont.) / Planning</a></li><li><a class="is-note-link" href="18_morePlanning_10_4_19.html">17. Planning (cont.)</a></li><li><a class="is-note-link" href="19_knowledgeEngineering_10_7_19.html">18. Knowledge Engineering</a></li><li><a class="is-note-link" href="20_yetMorePlanning_10_9_19.html">19. Planning (cont.)</a></li><li><a class="is-note-link" href="21_understandingCommonSense_10_11_19.html">20. Understanding and Common-Sense</a></li><li><a class="is-note-link" href="22_commonSense_10_16_19.html">21. Common-Sense Reasoning (cont.)</a></li><li><a class="is-note-link" href="23_fractalReasoning_10_18_19.html">22. Fractal Reasoning</a></li><li><a class="is-note-link" href="24_explanationReasoning_10_21_19.html">23. Explanation-Based Reasoning</a></li><li><a class="is-note-link" href="25_analogicalReasoning_10_23_19.html">24. Analogical Reasoning</a></li><li><a class="is-note-link" href="26_moreAnalogicalReasoning_10_25_19.html">25. Analogical Reasoning (cont.)</a></li><li class="active-note-page"><a class="is-note-link" href="27_moreAnalogyVersionSpace_10_28_19.html">26. Analogical Reason (cont). / Version Spaces</a></li><li><a class="is-note-link" href="28_versionSpaces_10_30_19.html">27. Version Spaces</a></li><li><a class="is-note-link" href="29_constraintProp_11_1_19.html">28. Constraint Propagation</a></li><li><a class="is-note-link" href="30_moreConstraintProp_11_4_19.html">29. Constraint Propagation (cont.)</a></li><li><a class="is-note-link" href="31_diagnosis_11_6_19.html">30. Diagnosis</a></li><li><a class="is-note-link" href="32_mistakeCorrection_11_8_19.html">31. Learning from Mistakes</a></li><li><a class="is-note-link" href="33_metacognition_11_11_19.html">32. Metacognition</a></li><li><a class="is-note-link" href="34_advancedTopics_11_13_19.html">33. Advanced Topics</a></li><li><a class="is-note-link" href="35_principles_11_15_19.html">34. Principles of AI</a></li><li><a class="is-note-link" href="36_wrapUp_11_18_19.html">35. Wrapping Up</a></li></ul>
</nav>
<main>
<a class="side-link is-note-link" href="26_moreAnalogicalReasoning_10_25_19.html"></a>
<article>
<!-- Actual note text goes into 'pre' -->
<pre id="text-width-ruler"></pre>
<pre class="main-note-text">//****************************************************************************//
//****** Analogical Reason (cont). / Version Spaces - October 28th, 2019 ****//
//**************************************************************************//

- Jake's descent into madness, part 1: 26 hours without sleep
    - I feel like my mind's currently stuck in tar and shared with a Rottweiler who is most definitely Not A Very Good Boy. It's simultaneously very slow and very twitchy. Also, my face feels like something wants to jump out of it.
        - May the joys of sleep deprivation - and my first (hopefully last) all nighter at Tech - begin

- So, we were working on analogical reasoning last time; let's try to get that wrapped up
    - How do we transfer a source case to the target? One principle of intelligence we talked about: we transfer only what is NESTED (per the principle of systematicity)
        - What presumably sets us apart from all other animals is that we can think in terms of relationships; if things aren't nested, then we're just naming properties, but a NESTED link implies there's some deeper relationship going on!
            - Unlike machine learning and almost all other AI fields, we'll ONLY care about these relationships and ignore the feature values themselves
        - According to analogical theories of intelligence, this stuff is human's secret sauce; this kind of thinking is what we have that others don't
            - Notice this is a POWERFUL idea: where do new ideas come from? Where does creativity come from? Analogies seem to be at least one large piece in the puzzle
- There are several things going on here
    - A fundamental idea in AI is "where do ideas come from?"
        - Finding cats in pictures, of course, is not so fundamental
    - We transfer ideas across very different situations, focusing on these relations unlike all other animals; this is our first time in this class tackling
        - Almost all scientists believe in Darwin's theory of evolution, including cognitive scientists - but many cognitive scientists believe Darwin made a critical mistake
            - Darwin and all evolutionary biologists claim that evolution occurs in very small, incremental, contiguous steps - but increasingly, cognitive scientists think that while there's indeed biological evolution, these biologists were so focused on biology that they missed cognition
                - Cognition seems to have occurred in a jump at some point; there's biological continuity, they say, but a cognitive leap, and cognitive scientists increasingly claim humans seem to be unique in this. Other creatures can recognize objects and features quite well, but abstract relationships are something different; perhaps crows and dolphins can do basic counting and numerical relationships, but nothing close to us
            - These are some very big ideas - and controversial ideas! - but here's the question: are we unique in the universe? If we are, what does that say about us trying to build AIs?
--------------------------------------------------------------------------------

- So, let's talk some more about where ideas come from!
    - Here's a BMW car whose design was inspired by the Boxfish, and another picture of a bullet train inspired by a Kingfisher's bill
        - We sometimes think of ideas like this as revolutionary, but they often just come through analogy!
        - Humans can even COMBINE multiple analogies, which no AI can currently do!
    
- So, that's analogical reasoning, come and gone

- We'll now move on to VERSION SPACES, and what better way to introduce it than a Seinfeld video?
    - "Humans make mistakes all the time, and one of our most common mistakes is over-generalization"
        - One thing we've been saying is that we should build human-like AIs, but us humans make mistakes - do we want our AIs to make those some mistakes? Should we reproduce our biases and limitations in our machines?
            - Psychologists have identified 57 major human biases, and there's likely more
            - The most common error humans make of all is over-generalizing; I meet someone, see they have 2 arms, and say "gee, all humans must have 2 arms!" I meet a person from the Netherlands and he's mean, and I decide "huh, those Dutch are rude!"
        - Humans also have a VERY limited short-term memory; all our telephone digits are less than 10 digits for a reason! We're limited!

- VERSION SPACES talks about how we can create human-like AI while guarding against over-generalizing, hopefully extending that to more biases over time
    - We've talked about incremental concept learning before, and how learning from new things is heavily based on your background knowledge
        - We generalize when we get a positive example and specialize when we get a negative example, and hopefully converge; how can we do better?
    - VERSION SPACES tries to get around this by keeping both the most general possible model and the most specific possible model in our heads, with the 2 hopefully converging
        - So, imagine we go to a restaurant to get breakfast on Friday and Sam's, and it was very cheap and I was sick afterwards
        - Next Friday, go to Sam's for lunch on a Saturday, and I ALSO got sick!
            - Is it correct to say I'll get sick every time I go to Sam's? No, of course not!
        - So, we want to make the most specific and general model here

- Hopefully this will become more clear as we go through mpore examples; see you on Wednesday!</pre>
</article>
<a class="side-link is-note-link" href="28_versionSpaces_10_30_19.html"></a>
</main>
</body>
</html>