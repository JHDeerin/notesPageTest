<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0" name="viewport"/>
<title>Jake's CS Notes - Computer Vision</title>
<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet"/>
<link href="../../css/testStyle.css" rel="stylesheet"/>
<link href="../../css/notePageStyle.css" rel="stylesheet"/>
<link href="../../css/cs4476Theme.css" id="class-theme-styles" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" rel="stylesheet"/>
</head>
<body>
<script defer="" src="../../js/wrapText.js"></script>
<script defer="" src="../../js/pageTransitions.js"></script>
<script async="" defer="" src="../../js/loadMathJax.js"></script>
<nav class="nav-top">
<ul>
<li class="link-with-slash"><a href="../../index.html"><i class="fas fa-home"></i></a></li>
<li><a href="#" id="class-title-link">Computer Vision</a></li>
</ul>
<ul class="note-links-slider"><li><a class="is-note-link" href="0_firstDay_8_19_19.html">0. First Day</a></li><li><a class="is-note-link" href="1_projectiveGeometry_8_21_19.html">1. Projective Geometry</a></li><li><a class="is-note-link" href="2_cameraProjection_8_26_19.html">2. Camera Projection</a></li><li><a class="is-note-link" href="3_reflectanceModelsImages_8_28_19.html">3. Reflectance Models / Real-World Images</a></li><li><a class="is-note-link" href="4_filterNeuralNets_4_9_4_19.html">4. Image Filtering / Intro. Neural Nets</a></li><li><a class="is-note-link" href="5_moreCNN_9_9_19.html">5. Convolutional Neural Nets (cont.)</a></li><li><a class="is-note-link" href="6_fourierTransform_9_11_19.html">6. Crash-Course Fourier Transforms</a></li><li><a class="is-note-link" href="7_featuresHarris_9_16_19.html">7. Feature Detection / Harris Detector</a></li><li><a class="is-note-link" href="8_SIFTFeatureMatch_9_18_19.html">8. SIFT and Feature Matching</a></li><li><a class="is-note-link" href="9_edgeDetectionHough_9_23_19.html">9. Edge Detection and Hough Transforms</a></li><li><a class="is-note-link" href="10_imageAlignment_9_25_19.html">10. Feature-Based Image Alignment</a></li><li><a class="is-note-link" href="11_poseEstimation_9_30_19.html">11. Pose Estimation</a></li><li><a class="is-note-link" href="12_fundamentalMatrices_10_2_19.html">12. Fundamental Matrices</a></li><li><a class="is-note-link" href="13_midtermReview_10_7_19.html">13. Midterm Review &amp; Fear-Mongering</a></li><li><a class="is-note-link" href="14_structureMotionEstimation_10_16_19.html">14. Structure from Motion / Motion Estimation</a></li><li><a class="is-note-link" href="15_introDeepLearning_10_21_19.html">15. Intro. to Deep Learning</a></li><li><a class="is-note-link" href="16_stereoMatching_10_23_19.html">16. Stereo Matching</a></li><li><a class="is-note-link" href="17_denseMotion_10_28_19.html">17. Dense Motion Estimation</a></li><li><a class="is-note-link" href="18_panoramasHDR_10_30_19.html">18. Panoramas and HDR</a></li><li><a class="is-note-link" href="19_pytorchLearn_11_4_19.html">19. Pytorch Deep Learning Example</a></li><li><a class="is-note-link" href="20_objectRecognition_11_6_19.html">20. Object Recognition Basics</a></li><li><a class="is-note-link" href="21_classicDetection_11_11_19.html">21. Classical Object Detection</a></li><li class="active-note-page"><a class="is-note-link" href="22_SVMNeuralNets_11_13_19.html">22. SVMs and Neural Nets</a></li><li><a class="is-note-link" href="23_deepLearning_11_18_19.html">23. Deep Learning (cont.) / Segmentation</a></li><li><a class="is-note-link" href="24_segmentation_11_20_19.html">24. Image Segmentation</a></li><li><a class="is-note-link" href="25_embodiedAI_11_25_19.html">25. Embodied AI</a></li><li><a class="is-note-link" href="26_bioRobots_12_2_19.html">26. Biologically-Inspired Robotics</a></li></ul>
</nav>
<main>
<a class="side-link is-note-link" href="21_classicDetection_11_11_19.html"></a>
<article>
<!-- Actual note text goes into 'pre' -->
<pre id="text-width-ruler"></pre>
<pre class="main-note-text">//****************************************************************************//
//************* SVMs and Neural Nets - November 13th, 2019 ******************//
//**************************************************************************//

- Alright; we're still talking about image classification, where we're trying to train a function that'll swallow an input image, chew on it for a little while, and then spit out what it thinks it's an image of

- First off, let's finish talking about SVMs (support vector machines)
    - As we mentioned, this involves trying to draw a margin between different classes, and get our boundary to be as close to the "middle" of the two classes as possible (i.e. maximizing how big the margin is)
        - This generalizes to larger dimensions and larger numbers of classes
    - This works great, BUT: how can we deal with non-linear boundaries?
        - Boosting deals with this basically by having not 1 line, but HUNDREDS of lines; each learner is essentially another boundary, so we can have a lot of nuance by varying the learner weights
        - The way SVMs deal with this, though, is different: if we can't separate it at our current dimension, we'll instead somehow map the data to a HIGHER dimension until we CAN linearly separate it!
            - This is known as the KERNEL TRICK, and it turns out to come up in several other fields
                - It's called the kernel trick since we can compute this via a kernel (the product of 2 datasets), just like we did when Gaussian filtering
    - How does this nonlinear SVM "trick" work?
        - Imagine we've got some data on a flat, 1D line, like so:

                o  o   oo   o  x xx x o  o  o  oo

            - We can separate this pretty easily with 2 lines...

                o  o   oo   o |x xx x|o  o  o  oo

            - ...but we can't do so linearly! So, instead, we can do a 2D mapping where the Y-axis'll be y = x^2

                o                               o
                  o                            o
                      oo              o  o
                            o     x x
                              x x

        - Now, we can draw a straight line to separate all the "x" values, and it works!
            - Note that in order to get something that's possibly linearly separable, this new dimension has to be a NONLINEAR transformation; if we just used "y = 2x" or something, we'd just end up with a straight line again, and then we're back to square one!
    - So, which transformation makes our data "most separable," and how do we find it? That's a good question, and one that didn't have consensus!
    - In general, though SVMs work by:
        - Picking an image representation (like HOG)
        - Picking a kernel function for that representation, and then...
        - Computing the matrix of kernel values for all our training examples
        - Feeding this into some SVM solver to get our "support vectors"/boundaries
        - Then finally throwing our test data at it
    
- "This SVM stuff got computer vision nerds going for a good 10 years, before deep learning had to come and ruin it"
    - So, pros of SVMs:
        - For a time, they were SUPER well supported with libraries
        - They tend to work very well in practice, even with relatively small training sets
    - Cons:
        - SVMs are still fundamentally binary classifiers, so you need to combine multiple SVMs to get multi-class results
        - Training times can take quite awhile

- Alright, with SVMs done, let's wander into the modern age and start talking about NEURAL NETS!
    - This all started with the ImageNet database in 2012, which was a HUGE dataset that was arranged hierarchically and was much, much more diverse than many existing datasets, with tons of clutter
        - Existing algorithms were doing okay, but there was still like a 30% failure rate, and increases of just 1-2% were considered HUGE advances
    - In 2012, though, we got a breakthrough: AlexNet
        - While CNNs had been used before on some things (there were a few papers published on it in 2011, and there was a lot of foundational work done in the 1980s by Fukushima and Yann LeCun), and neural nets had been applied to speech recognition in 2010, this was the first time someone used it in a high-profile computer vision context
        - "These guys came along and dropped a paper that had a 15% error rate - which was 10% better than ANY other model. This was HUGE!"
            - They trained a fairly shallow neural net with SGD
    - Of course, people started publishing papers on deep learning IMMEDIATELY
        - In 2014-2015, people started to realize that making deeper neural nets with more and more layers kept getting better results (e.g. VGG, ResNet, etc.)
            - With deeper networks, we need to do a few tricks like gradient vanishing to get them to train effectively, but the net result is better output performance
            - In particular, RESIDUAL MAPPING becomes necessary once we have more than ~50 layers to make the training calculations practical

- Alright; we're out of time, so we'll finish this next week! Don't forget to work on Project 6 over the weekend!</pre>
</article>
<a class="side-link is-note-link" href="23_deepLearning_11_18_19.html"></a>
</main>
</body>
</html>