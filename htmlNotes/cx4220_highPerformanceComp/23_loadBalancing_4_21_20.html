<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0" name="viewport"/>
<title>Jake's CS Notes - Intro. to HPC</title>
<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet"/>
<link href="../../css/testStyle.css" rel="stylesheet"/>
<link href="../../css/notePageStyle.css" rel="stylesheet"/>
<link href="../../css/cx4220Theme.css" id="class-theme-styles" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" rel="stylesheet"/>
</head>
<body>
<script defer="" src="../../js/wrapText.js"></script>
<script defer="" src="../../js/pageTransitions.js"></script>
<script async="" defer="" src="../../js/loadMathJax.js"></script>
<nav class="nav-top">
<ul>
<li class="link-with-slash"><a href="../../index.html"><i class="fas fa-home"></i></a></li>
<li><a href="#" id="class-title-link">Intro. to HPC</a></li>
</ul>
<ul class="note-links-slider"><li><a class="is-note-link" href="0_firstDay_1_7_20.html">0. First Day</a></li><li><a class="is-note-link" href="1_parallelGoals_1_9_20.html">1. Parallel Algorithm Design Goals</a></li><li><a class="is-note-link" href="2_algoExamplesMPI_1_14_20.html">2. Algorithm Examples / Intro. to MPI</a></li><li><a class="is-note-link" href="3_hw1MPI_1_16_20.html">3. Homework 1 Review / Intro. to MPI</a></li><li><a class="is-note-link" href="4_communicationLatency_1_21_20.html">4. Communication, Deadlock, and Latency</a></li><li><a class="is-note-link" href="5_permuationsCollectiveComm_1_23_20.html">5. Permutations and Collective Communication</a></li><li><a class="is-note-link" href="6_collectivesPrefixSum_1_28_20.html">6. Collection Example / Prefix-Sum</a></li><li><a class="is-note-link" href="7_morePrefixSum_1_30_20.html">7. Prefix-Sum Algorithm</a></li><li><a class="is-note-link" href="8_prefixCAllToAll_2_4_20.html">8. Prefix Sum C Example / All-to-All</a></li><li><a class="is-note-link" href="9_bitonicSort_2_6_20.html">9. Bitonic Sort</a></li><li><a class="is-note-link" href="10_parallelQuickSort_2_11_20.html">10. Parallel Quick Sort</a></li><li><a class="is-note-link" href="11_sampleSort_2_20_20.html">11. Sample Sort</a></li><li><a class="is-note-link" href="12_midtermSol_2_25_20.html">12. Midterm Solutions</a></li><li><a class="is-note-link" href="13_introEmbeddings_2_27_20.html">13. Intro. to Embeddings</a></li><li><a class="is-note-link" href="14_mpiEmbeddings_3_3_20.html">14. Embeddings in MPI</a></li><li><a class="is-note-link" href="15_parallelMatrices_3_5_20.html">15. Parallel Matrix Operations</a></li><li><a class="is-note-link" href="16_2dMatrixAlgo_3_10_20.html">16. 2D-Matrix Algorithms</a></li><li><a class="is-note-link" href="17_optimal2DMatrix_3_12_20.html">17. Optimal 2D Matrices / Caching</a></li><li><a class="is-note-link" href="18_hw3Review_3_31_20txt.html">18. Homework 3/Exam 2 Review</a></li><li><a class="is-note-link" href="19_introFFT_4_7_20.html">19. Intro. Fast Fourier Transform</a></li><li><a class="is-note-link" href="20_parallelFFT_4_9_20.html">20. Parallel FFT</a></li><li><a class="is-note-link" href="21_parallelGraphAlgos_4_14_20.html">21. Parallel Graph Algorithms</a></li><li><a class="is-note-link" href="22_moreGraphAlgos_4_16_20.html">22. Graph Algorithms (cont.)</a></li><li class="active-note-page"><a class="is-note-link" href="23_loadBalancing_4_21_20.html">23. Load Balancing (cont.)</a></li></ul>
</nav>
<main>
<a class="side-link is-note-link" href="22_moreGraphAlgos_4_16_20.html"></a>
<article>
<!-- Actual note text goes into 'pre' -->
<pre id="text-width-ruler"></pre>
<pre class="main-note-text">//****************************************************************************//
//**************** Load Balancing (cont.) - April 21st, 2020 ****************//
//**************************************************************************//

- Currently, if I do raw grading scores, there are 3 people in the A range, 14 in the B range, and 6 in the C range
    - I'd tried to give enough extra-credit to avoid having to use a class-wide curve, but given the extraordinary circumstances with the coronavirus, I do think some extra leniency is warranted
    - Because of that, I'm considering a "letter-sign shift" in the grade assignments, where a B+ becomes and A-, an A becomes an A+, etc.
        - This isn't a huge shift - just ~3.3% - but hopefully it should give us a more normal-ish looking curve
    - In addition, it also seems that the final being a full 30% of the course when I've been less available for office hours since the break isn't fair, so I'm going to have the final work like this:
        - If the final raises your grade, you can count it as 30%
        - OTHERWISE, it will only count for 15% of your grade (meaning your total course grade will sum to 85%, rather than 100%)

- Programming Project 3 is due tonight, so PLEASE make sure you're working on that!

- Homework 4, for extra credit, is still out, and also due tonight
    - For problem 2, you can think of this Toeplitz matrix as being like a polynomial multiplication problem, like with FFT
        -

- "My philosophy is that turning something in late is better than turning in nothing at all, so if you need extra time reach out to me 1-on-1 and, while you probably won't get full credit, something can be arranged"
--------------------------------------------------------------------------------

- Last time, we were talking about LOAD BALANCING
    - One prominent feature of physical simulations is that data tends to have some sort of locality/spatial relations, and the density of the data at points can shift over time
        - Think of a wind tunnel simulation, where the air can shift around and move
    - We had a STATIC load balancing problem, where we wanted to minimize computational imbalances, and minimize communication across cuts - and these 2 goals are usually opposed!
        - Typically, if we end up with cuts that cross a small number of edges, it means
    - The DYNAMIC load balancing problem, then, also tries to minimize the movement of data from the old partitions to the new partitions we choose
        - Minimizing the movement of data from the old to the new partition is the (TODO: on lecture)
        - We tend to prefer incremental algorithms that can update the data in small increments, and small changes in the input result in gradual changes to the partitions

- So, those are our problems; let's take a look at some solutions!
    - There are 2 types of models for these problems:
        - GEOMETRIC models are where coordinates for our data items are available, and are great for problems where the data is in an actual physical space
        - COMBINATORIAL models are more abstract for non-physical problems, and are where we don't have any physical locations but we DO have connectivity information for our data items

- Let's look at some geometric solutions!
    - The RECURSIVE COORDINATE BISECTION (RCB) algorithm divides work into 2 equal parts by cutting it with a flat line/plane, then recursively divides each of THOSE portions to end up with an equal amount of work, lternating the direction we cut
        - Why alternate the dimensions (i.e. horizontal, then vertical, instead of just all horizontal)? Because of a ratio: Surface Area to Volume!
            - By alternating cuts, we're keeping our subdomains as close to square as possible, trying to minimize the size of our cuts
        - This algorithm is hierarchical, and is IMPLICITLY incremental with the cuts changing gradually to match the data, making it a good fit for dynamic load-balancing problems
        - So:
            - Pros:
                - Fairly simple and efficient to implement
                - Regular subdomains
                - Doesn't need connectivity information
            - Cons:
                - No explicit control of communication costs (since we don't use any connectivity information)
                - Can generate disconnected domains
                    - Basically, the partitions it generates aren't guaranteed to line up naturally with the problem space, which can make it more awkward/inefficient to calculate (e.g. )
                - Partition quality can be meh
                - Needs geometric coordinates
        - Still, though, this algorithm is commonly used in particle simulations, volume rendering, crash simulations, etc.
    - Another approach: the SPACE-FILLING CURVE PARTITION (SFC)
        - The idea here is that we have a space-filling curve that completely fills a domain, and we can apply it recursively to obtain however much granularity as we need
            - Given a coordinate, we can find its partition quickly, and vice-versa
        - We can use this for partitioning as follows:
            - Run a space-filling curve on a grid containing all our data points
            - Order objects based on their 1D position along the curve
            - Evenly split the data along that 1D curve (i.e. so the points are evenly distributed)
        - Doing this gives us non-rectangular but still pretty compact sub-domains, and figuring out where to divide is SUPER simple once we have this space-filling curve function (lie Hilbert's curve)
            - We can make this algorithm incremental, too, by taking a given grid square and recursively splitting it where we need more data!
        - So:
            - Pros:
                - Simple and fast
                - Maintains geometric locality (good for dynamic balancing)
                - Linear ordering of objects can give great cache performance
                    - Partitioning and cache-blocking are distinct, but definitely related
            - Cons:
                - No explicit control of communication costs (again, it's wholly determined by the data's position)
                - Can still generate disconnected subdomains/partitions
                - Partitions are often lower quality than PCB
                - Still need geometrics coordinates

- Then, for combinatorial solutions
    - First up, MULTI-LEVEL GRAPH PARTITIONING!
        - The idea here is that we construct small approximations of our graph repeatedly until there's one we know how to partition easily, we partition that easier problem, and then re-scale the problem back up to the original graph (making some slight changes as we scale it up to keep it good)
        - This multi-level approach has a BUNCH of sub-approaches; the default approach is okay for static partitioning, but for dynamic partitioning some approaches use a "diffusive strategy" to take some information from the original graph into account, keeping the changes incremental
        - So:
            - Pros:
                - High-quality partitions known for MANY types of graphs and applications (e.g. highly optimized engineering models, which take edges into accounts)
                - Can control communication costs
                - Widely used for static partitioning
            - Cons:
                - More expensive than geometric approaches
                - Difficult to make incremental
        - So, what are some applications of graph partitioning? There's tons!
            - Finite element analysis (?)
            - "Multi-physics" simulations (rarely need to rebalance, but need high-quality partitions to start)
            - Linear solvers
                - These are square and structurally symmetric, and decomposing based on the mesh indices is a natural fits

- This graph-based approach to load balancing is very popular in scientific computing, but it has a flaw that becomes evident in non-spatial applications: it assumes the number of edge cuts is the same as the communication volume
    - In reality, this ISN'T always true! Some edges get used much more than others
    - Graph models also tend to assume a symmetri, square (???)
    - So, is the graph based model good enough?
        - In mesh-based applications, probably! It works well in prctice and the structure of meshes guarantees low vertex degrees and decent partitions
        - For irregular networks, no, it doesn't;

- If you want to play around with some of these approaches, a good resource is the Zoltan Toolkit (which was party developed at Georgia Tech!), which lets you write code and freely switch between these algorithms

- So, to compensate for the problems of the graph model, some researchers have tried to devise the HYPERGRAPH MODEL
    - We won't have time to cover the details, but be aware that it's a thing

- Okay, I'll have office hours from 1:00 to 2:00 today to talk about the project if you have any questions; thanks for showing up today and sticking with it through this semester!
    - I'll
</pre>
</article>
<a class="side-link is-note-link" href="23_loadBalancing_4_21_20.html"></a>
</main>
</body>
</html>