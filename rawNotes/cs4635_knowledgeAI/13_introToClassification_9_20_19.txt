//****************************************************************************//
//************ Classification Basics - September 20th, 2019 *****************//
//**************************************************************************//

- Alright; last time, we wrapped up case-based reasoning, and we're now going to move onto one of the most important topics in all of AI: classification!
    - This is easily what 3/4ths of machine learning is trying to do right now: put stuff into categories ("there's a dog in that picture," "this building is a classroom", etc.)
    - What really is classification, though, and why is it important? And HOW can we do it?
--------------------------------------------------------------------------------

- Suppose we show you a bunch of animal pictures, and then we ask you which ones are birds - but what if we then ask you which ones can swim? Which ones build nests?
    - How do scientists decide if a new animal is a "bird," anyway? They look to see if it has similar features to examples we already know about, right?
        - Why is classification so ubiquitous? Humans seem to do classification and pattern-recognition CONSTANTLY, and it seems fundamental to many other thinking processes; it doesn't make sense to ask a robot to "get me a cup of coffee" if it can't decide what in the kitchen is a coffee!
            - Similarly, you might describe your symptoms to a doctor, and they'll then tell you what you have and give you a prescription - most doctors are classifiers!
    - So, classifiers seem ubiquitous - and good classification is CENTRAL for good action! You can't cross the street properly if you don't figure out if the sign says "STOP" or "GO"

- Suppose we're creatures that have some "m" number of actions we can do, and we can do "n" actions at a time - then we'd have n^m possible choices of what to do!
    - A doctor might have a VERY large number of medicines and combinations of medicines to give you, and he has to decide relatively quickly what to give you
        - There's also a huge number of things we perceive at any given time: the temperature in the room, the shapes on the wallpaper, the rigidity of the chair, every hair on a person's head, and even (occasionally) the professor's slides! And yet we can all listen to this lecture and make sense of it in near real-time
    - How can we do this? One theory is that BEFORE we process all of these percepts and their combinations separately, we map them to some intermediate concepts
        - This process of mapping different combinations of inputs to concepts is a form of classification!

- So, we've talked about procedural and episodic knowledge; now, let's talk about semantic knowledge
    - Semantics deal with meaning, and concepts are a type of meaning; frames, too, are a way of representing concepts, even if we didn't talk about it at the time

- Now, let's consider a more fundamental question: what really is a concept? We deal with them all the time, but what are they?
    - It turns out that there are many competing definitions, but we'll talk about a theory where there are 4 kinds of conept, in order from "formally defined in a rigorous manner" to "um...I know it when I see it"
        - AXIOMATIC CONCEPTS are concepts defined by a formal set of necessary AND sufficient conditions
            - An example of this would be the mathematical definition of a cricle; the idea of a circle is the same REGARDLESS of what culture you grow in, what your experiences are, etc.
        - PROTOTYPICAL CONCEPTS are concepts that are defined by a typical example with some variable properties
            - An example of this would be a chair; we might have a default idea of what a chair is, but there can be chairs with 3 legs, 4 legs, with/without cushions, in the shape of a flying saucer, etc.
        - EXEMPLAR CONCEPTS are abstract ideas that we can best define by different examples of the concept
            - Beauty is a classic example of this; we can name beautiful paintings or beautiful things in nature, but it's very hard to give a word-for-word definition people would all agree on (or even come up with one at all!), and it seems to differ somewhat across cultures
            - Similar types of exemplar concepts might be freedom, intelligence, justice, etc.
                - So, if we can't define these concepts ourselves, how can we expect to program them into AIs? Is the nature of knowledge that we can't turn it into an algorithm - are there some concepts that are, by definition, impossible to pin down exactly?
        - QUALIA are sensory concepts, like the color red or the taste of honey or heat - it's EXTRAORDINARILY subjective even between individuals
    - There are also some concepts that span multiple categories; the color "blue," for instance, has an exact definition in terms of light wavelength and energy units, but it also fits under qualia, as the way humans experience that color

- So, the hope in KBAI is that AIs will also have all of these kinds of concepts - not just the clearly 
    - Will AIs agree on what beauty is, or will they have opinions like us because of the nature of exemplar concepts? Will they have the same ideas of beauty or justice that we have?
    - What about trying to exactly define what "beauty" or "goodness" is for the sake of implementing it in an AI? Is that even possible? And if it is, wouldn't that lead to the programmer encoding their own biases into that robot, knowingly or not?

- So, let me tell you a rather disturbing story...
    - There was a beauty contest going on between young women, but it was a strange contest because the judge was a robot
        - Moreover, this robot kept giving fair-skinned women high marks, and giving dark-skinned women lower marks!
            - As it turns out, the robot was trained on winners of the Ms. America beauty concept, and since most winners of that concept have been fair-skinned, it was biased!
            - Even worse, all the programmers on this team were men; there was no diversity on the team to help safeguard against stuff like this
        - As it should've been, this contest was enormously controversial, and it's terrible enough that we've had these biases - isn't it more terrible to pass them on to our AI creations, too?
            - According to another student, there're apparently many stories like this in a book called "Weapons of Math Destruction"
    - In exemplar and biases, it seems there's an enormous danger of taking our own biases and encoding them into our AIs, because people assume all concepts have definitions independent of their opinions, when in fact that isn't clear
        - What should we do, then? Should we stop doing AI in these ethically-dangerous areas? If we don't, how can we possibly control for bias when we ourselves are biased? Is there a way to give our AIs reason to correct their biases - or is even that biased? Is there a such thing as an unbiased learning algorithm at all?
            - There's a fear in some AI ethicists that the elites in society will end up dictating the values these algorithms use, and it isn't clear how to avoid that, or how far the potential implications could be

- We'll come back to these questions next week - in the meantime, finish your projects!