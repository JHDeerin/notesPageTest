//****************************************************************************//
//***************** Risks and Consent - November 13th, 2019 *****************//
//**************************************************************************//

- Okay, one thing that we need to backtrack and go over today is GROUPTHINK, a psychological issue we didn't get to talk about last week
    - This is when we think something is true because, well, everyone else seems to think it's true too!
        - For instance, during the Iraq War, everyone thought that there were "weapons of mass destruction" in Saddam's regime, but it turned out they didn't exist - and while part of that came from faulty intelligence, a LOT of their confidence came from saying "well, the CIA and the FBI also think this, so we can't ALL be wrong!"

- On Monday, we talked about "risk," and how engineers view risk as a mix of harm's probability and magnitude
    - One weird thing the book does, though, is suggest that the public has a different view of risk that also includes if risks are "acceptable"; most people wouldn't say driving a car is "risky" - even though there's a chance of getting in a crash and dying - because they think those risks are acceptable
        - Skydiving, though? Most people aren't willing to do it, so it seems a lot riskier than driving a car even if the chance of dying is lower!
    - "The reason the book brings this up is because these different views of what's 'risky' can result in communication failures if you're not careful"
        - Our reading for Monday - from Kristin Shrader-Frechette - gives a particular example of this. She argues that scientists lost a lot of credibility with the public because they gave their "informed opinions" but weren't clear about if those were their scientific findings or just their opinions
        - The book gives 5 pieces of pretty obvious advice for how to communicate risk to the public, be it as an expert witness, a spokesperson, or what-have-you
            - Remember that the public has a looser definition of risk
            - Don't talk about "zero risk." Ever.
            - Remember that the public only trusts experts so much
                - "...I'm not sure why this gets thrown in there, but okay"
            - Remember that government risk assessors tend to be more conservative, and want to avoid harm at all costs and know EXACTLY how risky some things could be
            - Remember that these rules apply both when talking as an individual AND when your company is making public statements

- Let's also take a quick detour and talk about INFORMED CONSENT when we're putting people in a risky situation, and want to know if they agree to do it
    - Per our textbook, we'll say informed consent requires 3 things:
        - First off, the consent CANNOT be coerced; we might be able to use some legal loopholes, but ethically, we can't pressure someone into doing this thing; it has to be their free choice
            - "If I hold a gun to someone's neck and tell them to sign the form, that's NOT consent! If I'm teaching in a classroom and say 'Hey, can you sign this form? By the way, make sure you stay on my good side - I can fail you!', that's not okay either!"
            - Does getting paid for an experiment count as coercion? Hmmmm...
        - The person must have all information relevant to the risks involved clearly presented
        - The person must be rational and competent enough to understand that information
            - "If I hand a legal document to my 6 year old and ask him to sign it, that's not okay! He doesn't know how to read, let alone understand this stuff!"
    - This seems straightforward, but it isn't always this simple! It can be hard to know when consent has actually been given freely, and we sometimes don't know all the risks ("brand-new technologies are ESPECIALLY notorious for this")
        - For large engineering projects, it's also practically impossible to get informed consent from everyone; if we're building an oil rig, we can't send a form to everyone on the Gulf Coast saying "do you accept the risk of this rig leaking oil into the ocean?"
            - Denmark, interestingly, has a bunch of wind turbines compared to the U.S., and the way they did it was literally getting communities together and saying "what will it take for you to be okay with us building windmills in your backyard?"

- A couple more miscellaneous things from this chapter
    - PLEASE read 6.3 in the textbook, which talks about "normal accidents"
        - This is a controversial position saying that some level of accidents are unavoidable in complex systems, for 2 reasons:
            - Tight coupling, where many systems are tied closely together, allowing for chain reactions of badness to happen
            - Complex interactions, where distinct systems are loosely coupled BUT therefore have to interact in weird, complicated ways to do work
                - The argument goes that decreasing one of these means increasing the other; we can simplify the system by having a centralized computer, but now a computer virus can spread to all the rest of the systems!
            - This seems like an intuitive position, but it has been heavily debated by other people
    - There's also a section of the book that talks about "Tort law"
        - Say you've somehow gotten into trouble with the law as an engineer; most of the time, you won't go into "criminal court," but instead a special court where you're getting sued for negligence or whatever
            - To be successfully sued, the person has to show a "preponderance of evidence" of 4 things:
                - That you violated your legal duty towards the person
                - The person was injured
                - 
                    - "This is a MUCH lower standard than scientific proof, and even lower than the 'beyond reasonable doubt' line in criminal court"

- Alright; for Friday, read the ValueJet case posted on Canvas, and read ALL of Chapter 7 for next week. See you later!