<html>
<head>
    <meta charset="UTF-8">
    <meta name='viewport'
        content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
<title>(*TEST PAGE*) Jake's CS Notes - Intro to AI</title>
<link href="https://fonts.googleapis.com/css?family=Inconsolata" rel="stylesheet"/>
<link href="../css/testStyle.css" rel="stylesheet"/>
<link href="../css/notePageStyle.css" rel="stylesheet"/>
<link href="../css/cs3600Theme.css" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" rel="stylesheet"/>
</head>
<body>
<script defer="" src="../js/pageTransitions.js"></script>
<nav class="nav-top">
<ul>
<li class="link-with-slash"><a href="../index.html"><i class="fas fa-home"></i></a></li>
<li><a href="#">Intro to AI</a></li>
</ul>
<ul class="note-links-slider"><li class="active-note-page"><a class="is-note-link" href="0_AIHistoryAndAgents_5_15_18.html">0. CS 3600 First Day</a></li><li><a class="is-note-link" href="1_agentsAndSearchIntro_5_17_18.html">1. Agents and Intro to Search</a></li><li><a class="is-note-link" href="2_search_5_22_18.html">2. Search</a></li><li><a class="is-note-link" href="3_searchCont_5_24_18.html">3. Search (cont.)</a></li><li><a class="is-note-link" href="4_cspAndLogic_5_29_18.html">4. CSP and Logic Agents</a></li><li><a class="is-note-link" href="5_introProbability_5_31_18.html">5. Intro to Probabilistic Agents</a></li><li><a class="is-note-link" href="6_probabilityCont_6_5_18.html">6. Probability (cont.)</a></li><li><a class="is-note-link" href="7_introBayesNets_6_7_18.html">7. Introduction to Bayes' Nets</a></li><li><a class="is-note-link" href="8_dynamicBayesNets_6_12_18.html">8. Dynamic Bayes Nets</a></li><li><a class="is-note-link" href="9_introMachineLearning_6_14_18.html">9. Introduction to Machine Learning</a></li><li><a class="is-note-link" href="10_moreMachineLearning_6_19_18.html">10. Intro. Machine Learning (cont.)</a></li><li><a class="is-note-link" href="11_decisionTrees_6_21_18.html">11. Decision Trees/Review</a></li><li><a class="is-note-link" href="12_moreDecisionTrees_6_28_18.html">12. More Decision Trees</a></li><li><a class="is-note-link" href="13_markovDecisionProc_7_5_18.html">13. Markov Decision Processes</a></li><li><a class="is-note-link" href="14_policyAlgos_7_10_18.html">14. Policy Algorithms</a></li><li><a class="is-note-link" href="15_introRL_7_12_18.html">15. Reinforcement Learning</a></li><li><a class="is-note-link" href="16_localSearch_7_17_18.html">16. Local Search</a></li><li><a class="is-note-link" href="17_introNeuralNets_7_19_18.html">17. Introduction to Neural Networks</a></li><li><a class="is-note-link" href="18_backpropagation_7_24_18.html">18. Backpropagation</a></li></ul>
</nav>
<main>
<a class="side-link is-note-link" href="0_AIHistoryAndAgents_5_15_18.html"></a>
<article>
<!-- Actual note text goes into 'pre' -->
<pre>//****************************************************************************//
//***************** CS 3600 First Day - May 15th, 2018 **********************//
//**************************************************************************//

- 2:27 - Professor Byrd is testing the markers (despite the fact he'll be using 
the projector anyway...right?)
    - ...as of 2:29, he has continued to write on the board. Okay.
    - "TODAY" (the board proclaims), "
        - INTRO/SYLLABUS, 
        - SOME HISTORY OF AI, 
        - APPROACHES TO AI, 
        - WHAT IS AI, 
        - AGENTS/RATIONALITY, 
        - ENVIRONMENTS, 
        - (MAYBE) INTRO TO SEARCH"
    - As a postscript, the white wall enthuses: "IF YOU CAN'T READ THIS, COME 
    CLOSER!"
        - (yes, he writes in all-caps)
- Prof. Byrd has confirmed he will NOT use the projector; "I find I teach more 
slowly and carefully if I have to write stuff out"
----------------------------------------------

- So:
    - David Byrd, research scientist at Tech, NOT a full-time professor, 
    current PhD. student, main area of research is interaction of AI and the 
    stock market, but he likes teaching, so they sometimes let him do that
    - 2 TAs in the class; both are grad students, office hours will be posted 
    shortly
        - "Trust me, there'll be a lot of fiddly little stuff in the projects 
        you'll want their help for"

- So, 3600 is the gateway to the rest of the undergraduate AI curriculum in 
Computer Science
    - Occasionally, we get a trickle of interested CS-minor folks and a small 
    spattering of CS-inclined crazy people, but it's mostly CS majors
    - The main prerequisites are CS 1331 and 1332; you don't have to remember 
    EVERYTHING, but it'll help if you remember trees and search algorithms
    - A few syllabus notes:
        - The syllabus is located on "quantsoftware.gatech.edu"
            - "Having all the info on a wiki means I don't have to rewrite 
            everything just because, say, the school decided to change from 
            T-Square to Canvas"
        - For the first time, we're using Canvas instead of T-Square! "Just 
        when I'd finally figured T-Square out, they switched it on me"
        - Main interaction with me will be through Piazza
        - 4 projects, each equally weighted, ~2 weeks per project, worth 50% of 
        your total grade
            - All the projects will be PacMan related (woohoo!)
                - Scratch that! Most of the projects will be (single woo!)
                - NO LIBRARIES ALLOWED! You're expected to code all the search 
                methods, bayesian functions, decision trees, etc. in this class 
                from scratch; in later courses, we'll assume that you 
                understand how these work BECAUSE you took this class, and then 
                we'll be more lenient with using 3rd-party code
            - Project 1 will be search-based: trying to get PacMan to navigate 
            from one side of the maze to the other, first with 
            depth/breadth-first search, then using heuristics like A*
            - Project 2 will start introducing uncertainty with Bayes' Nets; 
            instead of deterministic algorithms, we'll try to use 
            probabilities. In this project, PacMan will ALSO have to evade the 
            ghosts, and the maze will be randomly generated. FURTHERMORE, 
            PacMan will have to detect these ghosts through "sensors" that 
            sometimes have unreliable data
            - Project 3 will be EITHER decision trees or neural nets, depending 
            on what we have time for
                - Decision trees are where we try to come up with the best 
                sequence of iterative decisions, where when we read the tree, 
                the correct answer should be in a leaf node at the bottom. The 
                problem is trying to build these trees correctly and efficiently
                - For Neural Nets, the problem is basically to code one of 
                these things from scratch - understanding all the matrix math, 
                backpropagation, etc.; this is complicated stuff, but TRUST ME, 
                we'll go through it in EXCRUCIATING detail
            - Project 4 will be Markov Decision Problems (MDPs) / Reinforcement 
            Learning, where the environment will be changing as we move through 
            it, we tell the system whether what it did was "good" or "bad", and 
            we try to train the system through that feedback
                - EACH of these projects have ~2.5% final-grade worth of extra 
                credit, so you can end up getting 60%/50% on the projects; this 
                can make up for a LOT of mistakes on the test, so please use 
                this!
            - "These projects are SUPER programming-heavy, they'll be 
            error-prone, etc., so PLEASE, start early! These are TOUGH 
            projects!"
        - The code is AUTOGRADED. The good: you can verify what your grade will 
        be before you turn it in! The bad: you can't argue with the autograder! 
            - Currently, this uses Python 2.7; we'll eventually get to updating 
            it to Python 3, and I DON'T want Python version to be a big deal, 
            but it'll still be 2.7 for this semester
        - 2 exams: a midterm and a CUMULATIVE final (worth 20% and 30%, 
        respectively)
            - You probably won't be asked to write code on the exam, but I'll 
            expect you to run "algorithms on paper", answer conceptual 
            questions, read code and answer "what does this do" questions, etc.
        - THE TEXTBOOK: I will NOT assign anything out of the textbook, and if 
        you take notes in class, you probably won't need the textbook.
            - "I personally think the textbook is a hard read, but it is a 
            valuable reference book"
    - Around the middle of class, I'll try to have a 5-minute break; two hours 
    is a long time, after all
        - "PLEASE come to every class if possible; we'll be building on top of 
        everything we do here, so if you miss anything, it'll snowball really 
        quick"

- The GOALS for this class:
    - Create functional agents
    - Represent knowledge
        - Specifically, in data structures that our programs can use to improve 
        their performance - ESPECIALLY useful if you plan on taking 
        Knowledge-Based AI in the future
    - Learning algorithms for solving AI problems
        - Similarly, learning to code these algorithms - I want you to use 
        libraries as a convenience, NOT because you don't know how these 
        algorithms work!
- ...and the major topics we'll cover:
    - Intelligent agents
    - Rational agents
    - Environments (other intelligent agents, changes over time, etc.)
    - Probabilistic reasoning (EVERYTHING after search will be probability 
    based)
        - You HAVE to know probability to survive this course - "It's not a 
        prerequisite; I wish it was. We'll briefly go over what you need to 
        know in-class"
    - Bayes' Nets (a way of simplifying probabilities so we don't have 
    exponential explosions of accounting for thousands of interacting 
    probabilities/variables)
    - Supervised Machine Learning
        - "ML is the hot sub-area in AI right now, so we've been adding more 
        and more of it to this course"
        - Involves sub-topics like decision trees, neural nets, etc.
        - Reinforcement Learning also fits under ML

- So, with that overview of the course out of the way, let's briefly go over 
what we're talking about with "artificial intelligence"
    - So, as you probably know, AI has been crazy-stupid hot in the news for 
    awhile now, and CS is the most popular major at Tech - "they keep asking us 
    to take more and more students, and then they don't hire any new faculty"
    - Inside of CS, AI is the most popular undergraduate thread, so you're in 
    the hottest of the hot fields. Salaries are great for this stuff; it's like 
    being a web programmer in 1994, where you'd just say "I know HTML" and they 
    give you a car. That's the good news.
        - The BAD news: it's not as sexy to make these things as the news makes 
        it out. It's cool. Really cool. But it's also basically a bunch of 
        math. HARD math.
        - Side note about open source: "Nobody likes their own code; I'm 
        constantly horrified by my old code, and if you're not, you probably 
        desperately need to improve. Researchers HATE releasing their code 
        because they're embarrassed by it."
    - So, what do we mean when we say "AI"?
        - ARTIFICIAL INTELLIGENCE has 2 main definitions that researchers 
        more-or-less agree on:
            - Making computers perform tasks that would otherwise require 
            intelligence
                - "...you'll notice this definition is kinda circular, but we 
                basically mean getting a computer to do things we normally only 
                see people or animals do, like drawing conclusions, finding 
                patterns, using past experience, and so on"
            - Making computers perform tasks that a person would BELIEVE 
            requires intelligence
                - "Intelligence" as a concept is still being discussed in 
                Psychology, Philosophy, Neuroscience, etc...as CS people, we 
                want to sidestep this debate and just skip to practical results
                - This is basically the "Turing Test" definition, where we try 
                to fool people into thinking the computer is smart
                    - ...as a sidenote, the original Turing Test was that a 
                    judge was talking to a computer pretending to be a human, 
                    and an actor pretending to be a computer, at the SAME TIME, 
                    which makes the computer's job easier. We're still not even 
                    at this level, and deep-learning still hasn't helped us 
                    with NLP and inferring meaning from conversations. We've 
                    gotten better at TRANSLATION, but not at getting computers 
                    to understand what they're hearing
        - "By the way, I won't test you on these definitions, so don't stress 
        out about them too much"
        - MORE CONCRETELY, there's a pragmatic definition many people use:
            - In algorithms, there are NP-hard problems, ones we don't know how 
            to solve in polynomial time; there are some techniques that people 
            use to speed up these computations
                - For instance, "dynamic programming" lets us avoid repetitive 
                work by remembering solutions to subprograms, which can speed 
                up certain problems
                - ...but, these techniques don't work for certain hard problems
            - SO, some people say that AI is "the process of getting 
            'reasonably accurate' estimates to NP-hard problems that we don't 
            know the answer to"
                - This has actually turned out to be a pretty useful definition

========== 5 Minute Intermission ==========

- So, let's now wrap up a bit of the "intro concepts" we should know for next 
time

- ...starting with the ACTUAL history of AI
    - For convenience, let's start with the 1956 "Dartmouth Conference", where 
    Marvin Minsky coined the term "Artificial Intelligence" for the class of 
    thinking problems he was working on
        - The initial goal was to make what we now call STRONG AI, or "general" 
        AI: getting a computer to at LEAST do anything a human can do, if not 
        more or better
    - At the beginning of the 1950s, they'd assumed this wouldn't be too hard; 
    they'd come up with a good computational framework, and they actually gave 
    the implementation task to a Dartmouth GRAD STUDENT as a summer project.
    - When they realized it was a little harder than that, they started to grow 
    the field, a lot of really high-profile AI projects were funded in the 
    1960s that could help advise generals on problems...
        - ...and while some amazing demos were made, the systems were brittle; 
        they only worked in EXTREMELY constrained situations, and going off the 
        script would break these things fast
    - By 1974 (when a certain David Byrd was born), DARPA had grown tired of AI 
    over-promising, and the first "AI Winter" set in where AI wasn't viewed as 
    a respectable field and no one would touch it
    - By the early 80s, though, interest in AI had revived, and instead of 
    aiming for building a human from scratch (complete with emotions and 
    feelings and morals and all), people decided to instead limit themselves 
    and start building EXPERT SYSTEMS instead - mimicking what humans do in 
    certain situations and capturing that knowledge, like a really complicated 
    flowchart
        - ...and that's really what these boiled down to: you would give input 
        (like medical symptoms) to a program, and it would spit out something 
        like "you have X with 74% probability"
        - These DID have some success, and were used in limited fields, but 
        they had a major limitation: they were rule-based systems designed by 
        human experts. They were expensive to make (trying to get human experts 
        to "brain dump" everything they *think* they know), and they were still 
        brittle; if it didn't have a certain situation or rule programmed into 
        it, it wouldn't be able to give an answer. They couldn't generalize.
    - So, in 1987 the second "AI Winter" set in as people grew disillusioned 
    with Expert Systems and their limitations, too.
    - By the 1990s, WEAK AI had become the goal: to make AI only for specific 
    systems, but with automation
        - This doesn't seem much better than Expert Systems, but with things 
        like "Bayesian Networks" and "Decision Trees", humans didn't have to 
        explicitly program in every single rule; the system, once designed, 
        could figure out some of these rules without manual work
            - This is still where a LOT of AI work in industry happens: 
            creating specific systems for specific uses, with an automation 
            component
    - And you know what...there wasn't an AI winter this time. Weak AI 
    by-and-large proceeded well, and at this point, in the early 2000s, 
    statisticians invaded the field. MACHINE LEARNING had begun picking up 
    steam as a subfield of AI: AI that could "self-improve" itself by repeated 
    exposure to data, "learning by example"
        - Before this point, all the other techniques were "human 
        comprehensible"; you could read a decision tree and figure out what the 
        computer's "thought process" was. With ML, we really can't do that; 
        even though it's been enormously successful, it doesn't figure out 
        results through normal logic; they're still really not well understood 
        theoretically
        - A big issue in ML today, then, is coming up with datasets that the 
        algorithm can learn from, which today largely requires humans to 
        manually label stuff...which is obviously quite labor-intensive
        - They also DON'T work well for everything: they seem to work very well 
        with sensing things (sight, hearing, etc.), but haven't made much 
        progress in general knowledge, finding meaning in language, etc; the 
        "hard AI" problems.
    - Annnnddd...that's more or less where we are today. There are some AI 
    researchers today convinced that a 3rd AI Winter is setting in, when people 
    realize that ML (as cool as it is) has been overhyped, but for now the news 
    is still excited. This is were we are.

- So, when we think about what we want an AI to do, we can think of it as a 
matrix with 2 axes: "Think/Act" and "Human/Rational"

                 Human | Rational
                ----------------
                |      |      | Think
                |  1   |  3   |
                ----------------------
                |      |      | Act
                |  2   |  4   |
                ---------------

    - 1) "Think/Human" is basically Cognitive Science; the AI we're building is 
    essentially a hypothesis of how the human mind works, and it brings in a 
    lot of psychological and philosophical components to the question that 
    "pragmatic" researchers might not care about. 
        - In this area, mistakes/incorrect answers are okay, since we're trying 
        to mimic how humans think
    - 2) "Act/Human" is similar to Weak AI/Turing Tests, where we don't care 
    how the computer is actually "thinking"; we just want it to fool people 
    into thinking it's rational
        - REPEAT: we DON'T CARE HOW we reach our conclusions, we're just 
        concerned with the results.
        - This is where most chatbots live, and ALSO where most Game AI lives
            - "As it turns out, playing against perfectly rational, 
            perfect-aiming game AI isn't that fun. You want the bots to be 
            interesting, not perfect."
    - 3) "Think/Rational" is where we're trying to create Spock: a being of 
    perfect logic. It's formally representing facts and deducing/making new 
    rules from the facts we know
        - The theory people LOVED this, since it boiled down to making 
        mathematical proofs (the programmers were less enthused)
        - These systems, though, tend to have the same brittleness problems; 
        they're not really "thinking", and if you ask them something they don't 
        have a fact for, they break down
        - So, these sorts of logical systems tend to work very well for "toy" 
        problems, but break down quickly when we generalize them. Exceptions 
        break 'em easily.
            - e.g. If you say "Spot has 3 legs" and "Dogs have 4 legs", a 
            system like this would say "Spot can't be a dog", even though 
            that's perfectly possible!
    - 4) "Act/Rational"; we're Computer Scientists, we don't care about 
    understanding people, heck, most of us DON'T understand people, so let's 
    just create something useful!
        - This is basically where most research is going on today: we don't 
        care HOW they do it, but we want to make agents that act optimally in 
        all circumstances. 
            - This is where ML lives, for instance
        - So, even if the agent isn't using human logic, it should make CORRECT 
        inferences, tell us if it's uncertain, and when it takes an action, 
        should lead to the best possible outcome
- To wrap up today: we'll say acting RATIONALLY does NOT mean acting 
"perfectly" or being "always right", but instead acting in an "expected 
optimal" manner: acting in the best possible manner given what it knows about 
its "world."
    - An example would be a robot that navigated a room correctly based on the 
    pattern of ceiling lights; it wouldn't work if we took it outside, but 
    given what it "knows" about the world, it's behaving correctly

- So, that's all for today, and on Thursday we'll wrap this up and start 
talking about Searching - see you then!

</pre>
</article>
<a class="side-link is-note-link" href="1_agentsAndSearchIntro_5_17_18.html"></a>
</main>
</body>
</html>